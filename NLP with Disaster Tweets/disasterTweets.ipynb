{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading train and test data\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# preprocess the text part of the data removing stopwords, tokenization and lemmatization\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text if not word in stop_words]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "train['text'] = train['text'].apply(clean_text)\n",
    "test['text'] = test['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id [    1     4     5 ... 10871 10872 10873]\n",
      "keyword [nan 'ablaze' 'accident' 'aftershock' 'airplane%20accident' 'ambulance'\n",
      " 'annihilated' 'annihilation' 'apocalypse' 'armageddon' 'army' 'arson'\n",
      " 'arsonist' 'attack' 'attacked' 'avalanche' 'battle' 'bioterror'\n",
      " 'bioterrorism' 'blaze' 'blazing' 'bleeding' 'blew%20up' 'blight'\n",
      " 'blizzard' 'blood' 'bloody' 'blown%20up' 'body%20bag' 'body%20bagging'\n",
      " 'body%20bags' 'bomb' 'bombed' 'bombing' 'bridge%20collapse'\n",
      " 'buildings%20burning' 'buildings%20on%20fire' 'burned' 'burning'\n",
      " 'burning%20buildings' 'bush%20fires' 'casualties' 'casualty'\n",
      " 'catastrophe' 'catastrophic' 'chemical%20emergency' 'cliff%20fall'\n",
      " 'collapse' 'collapsed' 'collide' 'collided' 'collision' 'crash' 'crashed'\n",
      " 'crush' 'crushed' 'curfew' 'cyclone' 'damage' 'danger' 'dead' 'death'\n",
      " 'deaths' 'debris' 'deluge' 'deluged' 'demolish' 'demolished' 'demolition'\n",
      " 'derail' 'derailed' 'derailment' 'desolate' 'desolation' 'destroy'\n",
      " 'destroyed' 'destruction' 'detonate' 'detonation' 'devastated'\n",
      " 'devastation' 'disaster' 'displaced' 'drought' 'drown' 'drowned'\n",
      " 'drowning' 'dust%20storm' 'earthquake' 'electrocute' 'electrocuted'\n",
      " 'emergency' 'emergency%20plan' 'emergency%20services' 'engulfed'\n",
      " 'epicentre' 'evacuate' 'evacuated' 'evacuation' 'explode' 'exploded'\n",
      " 'explosion' 'eyewitness' 'famine' 'fatal' 'fatalities' 'fatality' 'fear'\n",
      " 'fire' 'fire%20truck' 'first%20responders' 'flames' 'flattened' 'flood'\n",
      " 'flooding' 'floods' 'forest%20fire' 'forest%20fires' 'hail' 'hailstorm'\n",
      " 'harm' 'hazard' 'hazardous' 'heat%20wave' 'hellfire' 'hijack' 'hijacker'\n",
      " 'hijacking' 'hostage' 'hostages' 'hurricane' 'injured' 'injuries'\n",
      " 'injury' 'inundated' 'inundation' 'landslide' 'lava' 'lightning'\n",
      " 'loud%20bang' 'mass%20murder' 'mass%20murderer' 'massacre' 'mayhem'\n",
      " 'meltdown' 'military' 'mudslide' 'natural%20disaster'\n",
      " 'nuclear%20disaster' 'nuclear%20reactor' 'obliterate' 'obliterated'\n",
      " 'obliteration' 'oil%20spill' 'outbreak' 'pandemonium' 'panic' 'panicking'\n",
      " 'police' 'quarantine' 'quarantined' 'radiation%20emergency' 'rainstorm'\n",
      " 'razed' 'refugees' 'rescue' 'rescued' 'rescuers' 'riot' 'rioting'\n",
      " 'rubble' 'ruin' 'sandstorm' 'screamed' 'screaming' 'screams' 'seismic'\n",
      " 'sinkhole' 'sinking' 'siren' 'sirens' 'smoke' 'snowstorm' 'storm'\n",
      " 'stretcher' 'structural%20failure' 'suicide%20bomb' 'suicide%20bomber'\n",
      " 'suicide%20bombing' 'sunk' 'survive' 'survived' 'survivors' 'terrorism'\n",
      " 'terrorist' 'threat' 'thunder' 'thunderstorm' 'tornado' 'tragedy'\n",
      " 'trapped' 'trauma' 'traumatised' 'trouble' 'tsunami' 'twister' 'typhoon'\n",
      " 'upheaval' 'violent%20storm' 'volcano' 'war%20zone' 'weapon' 'weapons'\n",
      " 'whirlwind' 'wild%20fires' 'wildfire' 'windstorm' 'wounded' 'wounds'\n",
      " 'wreck' 'wreckage' 'wrecked']\n",
      "location [nan 'Birmingham' 'Est. September 2012 - Bristol' ... 'Vancouver, Canada'\n",
      " 'London ' 'Lincoln']\n",
      "target [1 0]\n"
     ]
    }
   ],
   "source": [
    "# check unique values in each columns except text\n",
    "for col in train.columns:\n",
    "    if col != 'text':\n",
    "        print(col, train[col].unique())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nan values in keyword and location columns\n",
    "\n",
    "train['keyword'] = train['keyword'].fillna('unknown')\n",
    "train['location'] = train['location'].fillna('unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
