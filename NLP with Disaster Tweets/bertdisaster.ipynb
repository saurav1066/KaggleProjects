{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the train and test sets\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling location and keyword with unknown and none\n",
    "train['location'].fillna('Unknown', inplace=True)\n",
    "test['location'].fillna('Unknown', inplace=True)\n",
    "train['keyword'].fillna('None', inplace=True)\n",
    "test['keyword'].fillna('None', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate targe and features\n",
    "\n",
    "X = train[['text', 'location', 'keyword']]\n",
    "y = train['target']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train validaztion split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-22b434eb261c>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['all'] = X_train['text'] + ' ' + X_train['location'] + ' ' + X_train['keyword']\n",
      "<ipython-input-6-22b434eb261c>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val['all'] = X_val['text'] + ' ' + X_val['location'] + ' ' + X_val['keyword']\n"
     ]
    }
   ],
   "source": [
    "# combine all features as a single string\n",
    "X_train['all'] = X_train['text'] + ' ' + X_train['location'] + ' ' + X_train['keyword']\n",
    "X_val['all'] = X_val['text'] + ' ' + X_val['location'] + ' ' + X_val['keyword']\n",
    "test['all'] = test['text'] + ' ' + test['location'] + ' ' + test['keyword']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 12.0kB/s]\n",
      "c:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\lenovo\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 2.42MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 4.46MB/s]\n",
      "Downloading config.json: 100%|██████████| 483/483 [00:00<00:00, 101kB/s]\n"
     ]
    }
   ],
   "source": [
    "# model with distilledbert\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "from transformers import TFDistilBertModel\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# encode the text\n",
    "X_train_encoded = tokenizer(X_train['all'].tolist(), padding=True, truncation=True, max_length=512)\n",
    "X_val_encoded = tokenizer(X_val['all'].tolist(), padding=True, truncation=True, max_length=512)\n",
    "test_encoded = tokenizer(test['all'].tolist(), padding=True, truncation=True, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "def create_model():\n",
    "    bert = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "    input_ids = Input(shape=(512,), name='input_ids', dtype='int32')\n",
    "    attention_mask = Input(shape=(512,), name='attention_mask', dtype='int32')\n",
    "    bert_input = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "    bert_output = bert(bert_input)['last_hidden_state']\n",
    "    output = Dense(1, activation='sigmoid')(bert_output[:,0,:])\n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|██████████| 268M/268M [00:36<00:00, 7.27MB/s] \n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFDistilBertModel.call of <transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertModel object at 0x000001C40F88AD60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFDistilBertModel.call of <transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertModel object at 0x000001C40F88AD60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFDistilBertMainLayer.call of <transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertMainLayer object at 0x000001C428C6B6A0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFDistilBertMainLayer.call of <transformers.models.distilbert.modeling_tf_distilbert.TFDistilBertMainLayer object at 0x000001C428C6B6A0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFEmbeddings.call of <transformers.models.distilbert.modeling_tf_distilbert.TFEmbeddings object at 0x000001C4289D6430>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFEmbeddings.call of <transformers.models.distilbert.modeling_tf_distilbert.TFEmbeddings object at 0x000001C4289D6430>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFTransformer.call of <transformers.models.distilbert.modeling_tf_distilbert.TFTransformer object at 0x000001C4289D6AC0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFTransformer.call of <transformers.models.distilbert.modeling_tf_distilbert.TFTransformer object at 0x000001C4289D6AC0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFTransformerBlock.call of <transformers.models.distilbert.modeling_tf_distilbert.TFTransformerBlock object at 0x000001C4289D6D30>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFTransformerBlock.call of <transformers.models.distilbert.modeling_tf_distilbert.TFTransformerBlock object at 0x000001C4289D6D30>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method TFMultiHeadSelfAttention.call of <transformers.models.distilbert.modeling_tf_distilbert.TFMultiHeadSelfAttention object at 0x000001C428AB01F0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TFMultiHeadSelfAttention.call of <transformers.models.distilbert.modeling_tf_distilbert.TFMultiHeadSelfAttention object at 0x000001C428AB01F0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "attention_mask (InputLayer)     [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_ids (InputLayer)          [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model (TFDistilB TFBaseModelOutput(la 66362880    attention_mask[0][0]             \n",
      "                                                                 input_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 768)]        0           tf_distil_bert_model[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            769         tf_op_layer_strided_slice[0][0]  \n",
      "==================================================================================================\n",
      "Total params: 66,363,649\n",
      "Trainable params: 66,363,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = create_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 512) for input Tensor(\"input_ids:0\", shape=(None, 512), dtype=int32), but it was called on an input with incompatible shape (None, 93).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 512) for input Tensor(\"attention_mask:0\", shape=(None, 512), dtype=int32), but it was called on an input with incompatible shape (None, 93).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 512) for input Tensor(\"input_ids:0\", shape=(None, 512), dtype=int32), but it was called on an input with incompatible shape (None, 93).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 512) for input Tensor(\"attention_mask:0\", shape=(None, 512), dtype=int32), but it was called on an input with incompatible shape (None, 93).\n",
      "762/762 [==============================] - ETA: 0s - loss: 0.7460 - accuracy: 0.5420WARNING:tensorflow:Model was constructed with shape (None, 512) for input Tensor(\"input_ids:0\", shape=(None, 512), dtype=int32), but it was called on an input with incompatible shape (None, 75).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 512) for input Tensor(\"attention_mask:0\", shape=(None, 512), dtype=int32), but it was called on an input with incompatible shape (None, 75).\n",
      "762/762 [==============================] - 1386s 2s/step - loss: 0.7460 - accuracy: 0.5420 - val_loss: 0.6828 - val_accuracy: 0.5739\n",
      "Epoch 2/3\n",
      "762/762 [==============================] - 1181s 2s/step - loss: 0.6922 - accuracy: 0.5494 - val_loss: 0.6822 - val_accuracy: 0.5739\n",
      "Epoch 3/3\n",
      "762/762 [==============================] - 1171s 2s/step - loss: 0.6908 - accuracy: 0.5555 - val_loss: 0.6865 - val_accuracy: 0.5739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c429839910>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "import tensorflow as tf\n",
    "\n",
    "# Convert input lists to tensors\n",
    "X_train_input_ids = tf.convert_to_tensor(X_train_encoded['input_ids'])\n",
    "X_train_attention_mask = tf.convert_to_tensor(X_train_encoded['attention_mask'])\n",
    "X_val_input_ids = tf.convert_to_tensor(X_val_encoded['input_ids'])\n",
    "X_val_attention_mask = tf.convert_to_tensor(X_val_encoded['attention_mask'])\n",
    "\n",
    "# Train the model with the converted tensors\n",
    "model.fit([X_train_input_ids, X_train_attention_mask], y_train, validation_data=([X_val_input_ids, X_val_attention_mask], y_val), epochs=3, batch_size=8)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 512) for input Tensor(\"input_ids:0\", shape=(None, 512), dtype=int32), but it was called on an input with incompatible shape (None, 82).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 512) for input Tensor(\"attention_mask:0\", shape=(None, 512), dtype=int32), but it was called on an input with incompatible shape (None, 82).\n"
     ]
    }
   ],
   "source": [
    "# predict on the test set\t\n",
    "test_input_ids = tf.convert_to_tensor(test_encoded['input_ids'])\n",
    "test_attention_mask = tf.convert_to_tensor(test_encoded['attention_mask'])\n",
    "y_pred = model.predict([test_input_ids, test_attention_mask])\n",
    "\n",
    "# create a submission file\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "submission['target'] = np.round(y_pred).astype(int)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
